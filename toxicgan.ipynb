{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt; The difference in average earnings between m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The myth is that the \"gap\" is entirely based o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The assertion is that women get paid less for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You said in the OP that's not what they're mea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;Men and women are not payed less for the same...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0  > The difference in average earnings between m...      0\n",
       "1  The myth is that the \"gap\" is entirely based o...      0\n",
       "2  The assertion is that women get paid less for ...      0\n",
       "3  You said in the OP that's not what they're mea...      0\n",
       "4  >Men and women are not payed less for the same...      0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('traindata.csv',nrows = 200)\n",
    "dropped = ['processed', 'offensiveness_score']\n",
    "rename = {'txt': 'comment', 'isOffensive': 'label'}\n",
    "df = df.drop(columns=dropped)\n",
    "df = df.rename(columns=rename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['comment'].tolist()\n",
    "labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_inputs = tokenizer(comments, padding=True, truncation=True, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "pooled_output = outputs['pooler_output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 2s 5ms/step - loss: 0.7825 - accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6687 - accuracy: 0.5900\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.6450\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6026 - accuracy: 0.6700\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6126 - accuracy: 0.6600\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6070 - accuracy: 0.6800\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6114 - accuracy: 0.6550\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6090 - accuracy: 0.6400\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5984 - accuracy: 0.6650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d635c700d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.fit(pooled_output, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(768, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = tf.keras.Input(shape=(768,))\n",
    "generated_output = generator(gan_input)\n",
    "gan_output = discriminator(generated_output)\n",
    "\n",
    "gan = tf.keras.Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "# Compile and train the GAN\n",
    "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 6ms/step - loss: 0.3965 - accuracy: 0.8350\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2588 - accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2217 - accuracy: 0.9150\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2361 - accuracy: 0.9100\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2242 - accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2196 - accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1998 - accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2108 - accuracy: 0.9150\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2372 - accuracy: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d6368e3a10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(pooled_output, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  toxic\n",
       "0   0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0\n",
       "1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0\n",
       "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0\n",
       "3   0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4   0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0\n",
       "5   00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0\n",
       "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9   00040093b2687caa  alignment on this subject and which are contra...      0\n",
       "10  0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0\n",
       "11  00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0\n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "13  0006f16e4e9f292e  Before you start throwing accusations and warn...      0\n",
       "14  00070ef96486d6f9  Oh, and the girl above started her arguments w...      0\n",
       "15  00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...      0\n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski      0\n",
       "18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...      0\n",
       "19  0009eaea3325de8c  Don't mean to bother you \\n\\nI see that you're...      0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = pd.read_csv('traintest.csv',nrows = 20)\n",
    "droppedt = ['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "# rename = {'txt': 'comment', 'isOffensive': 'label'}\n",
    "dftest = dftest.drop(columns=droppedt)\n",
    "# df = df.rename(columns=rename)\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = dftest['comment_text'].tolist()\n",
    "test_labels = dftest['toxic'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_inputs = tokenizer(test_comments, padding=True, truncation=True, return_tensors='tf')\n",
    "test_input_ids = encoded_test_inputs['input_ids']\n",
    "test_attention_mask = encoded_test_inputs['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = bert_model(test_input_ids, attention_mask=test_attention_mask)\n",
    "test_pooled_output = test_outputs['pooler_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "discriminator_predictions = discriminator.predict(test_pooled_output)\n",
    "discriminator_predictions = np.round(discriminator_predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_accuracy = accuracy_score(test_labels, discriminator_predictions)\n",
    "discriminator_precision = precision_score(test_labels, discriminator_predictions)\n",
    "discriminator_recall = recall_score(test_labels, discriminator_predictions)\n",
    "discriminator_f1 = f1_score(test_labels, discriminator_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Metrics:\n",
      "Accuracy: 0.65\n",
      "Precision: 0.16666666666666666\n",
      "Recall: 0.3333333333333333\n",
      "F1-Score: 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "print(\"Discriminator Metrics:\")\n",
    "print(\"Accuracy:\", discriminator_accuracy)\n",
    "print(\"Precision:\", discriminator_precision)\n",
    "print(\"Recall:\", discriminator_recall)\n",
    "print(\"F1-Score:\", discriminator_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = [\"I hate you.\", \"I like donuts.\"]\n",
    "toxic_encoded_inputs = tokenizer(toxic_comments, padding=True, truncation=True, return_tensors='tf')\n",
    "toxic_input_ids = toxic_encoded_inputs['input_ids']\n",
    "toxic_attention_mask = toxic_encoded_inputs['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_outputs = bert_model(toxic_input_ids, attention_mask=toxic_attention_mask)\n",
    "toxic_pooled_output = toxic_outputs['pooler_output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_output = generator(toxic_pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_comments = tokenizer.batch_decode(non_toxic_output.numpy(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[unused0] [unused0] [UNK] [unused0] [unused0] [UNK] [unused0] [UNK] [UNK] [unused0] [UNK] [unused0] [unused0] [UNK] [unused0] [UNK] [UNK] [unused0] [UNK] [unused0] [UNK] [unused0] [UNK] [UNK] [unused0] [UNK] [unused0] [unused0] [unused0] [unused0] [UNK] [UNK] [unused0] [UNK] [unused0] [unused0] [UNK] [unused0] [unused0] [UNK] [unused0] [UNK] [UNK] [UNK] [UNK] [UNK] [unused0] [unused0] [unused0] [UNK] [unused0] [UNK] [UNK] [UNK] [unused0] [UNK] [UNK] [unused0] [unused0] [unused0] [UNK] [UNK] [UNK] [UNK] [unused0] [unused0] [unused0] [UNK] [unused0] [UNK] [UNK] [UNK] [UNK] [unused0] [unused0] [unused0] [unused0] [unused0] [unused0] [UNK] [UNK] [UNK] [UNK] [UNK] [unused0] [unused0] [unused0] [UNK] [unused0] [unused0] [UNK] [unused0] [unused0] [UNK] [UNK] [unused0] [unused0] [unused0]\n",
      "[UNK] [unused0] [UNK] [unused0] [UNK] [UNK] [unused0] [UNK] [UNK] [UNK] [UNK] [unused0] [unused0] [unused0] [UNK] [UNK] [UNK] [unused0] [unused0] [UNK] [unused0] [UNK] [unused0] [unused0] [unused0] [UNK] [UNK] [unused0] [unused0] [UNK] [UNK] [UNK] [unused0] [UNK] [UNK] [unused0] [unused0] [unused0] [unused0] [UNK] [UNK] [UNK] [unused0] [unused0] [UNK] [unused0] [unused0] [unused0]\n"
     ]
    }
   ],
   "source": [
    "for comment in non_toxic_comments:\n",
    "    print(comment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
